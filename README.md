
# Objective

Perform Data Engineering(ETL) on bank dataset with Standalone spark cluster.

# Used Technologies :

1. Pyspark
2. SparkSQL
3. Core Python


# Solution


1)  Launch spark in local mode with a specified number of CPU cores.
2)  Read CSV file in Spark Data-frame.
3)  Remove unknown values and store them into a new Data-frame.
4)  Cast new types for columns of that Data-frame into new Data-frame.
5)  Basic use of pyspark.sql.functions.
6)  Replace the missing values with the average value of that columns.
7)  Write that transformed data frame into a new CSV file.
